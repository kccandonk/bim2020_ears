# -*- coding: utf-8 -*-
"""KCKP_BIMFinalProject_fixnorm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hZ25TMCSDJvULBBuqsFmykW4IOx9GHN7

# Set up
Mount Google Drive
"""

print("mounting drive...")
from google.colab import drive
drive.mount('/content/drive')

"""Import necessary packages"""

import os
import cv2
import sys
import argparse
import datetime
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix

os.environ['CUDA_VISIBLE_DEVICES'] = str(0)

if tf.test.gpu_device_name(): 
    print("Default GPU Device:{}".format(tf.test.gpu_device_name()))
else:
    print("Please install GPU version of TF")
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

"""#Define functions for importing data and training and evaluating model"""

def load_data_from_path(file_path):
    """
    Load data from npy files
    :param file_path: path to npy file with data
    :return: input features (images and landmarks) and target data as numpy arrays
    """
    print("Loading data...")
    
    #images = np.load(file_path + "small_images.npy")
    images = np.load(file_path + "all_images.npy")
    target = np.load(file_path + "all_labels.npy")
    landmarks = np.load(file_path + "all_landmarks.npy")

    return images, target, landmarks

def normalize_images(data):
    """
    Normalize a give matrix of data (samples must be organized per row)
    :param data: input data
    :return: normalized data with pixel values in [0,1]
    """

    # sanity checks!
    assert len(data.shape) == 4, "Expected the input data to be a 4D matrix"

    normalized_data = data / 255.0
    #normalized_data = normalized_data.round(3)

    return normalized_data

def split_data(input_im,input_landmarks,target,split):
    """
    :param input_im: input image data
    :param input_landmarks: input landmarks from images
    :param target: labels for data
    :param split: proportion of data to allocate to first dataset after split
    """
    # randomize indices for inputs
    N = input_im.shape[0]
    indices = np.arange(N)
    np.random.shuffle(indices)
    # first N*split random indices are for first dataset after split, remaining are for second dataset after split
    num_train = int(N*(split))
    train_indices = indices[:num_train]
    val_indices = indices[num_train:]
    # split dataset into 2 sets
    train_input_im = input_im[train_indices,:,:,:]
    train_input_landmarks = input_landmarks[train_indices,:,:]
    train_target = target[train_indices]
    val_input_im = input_im[val_indices,:,:,:]
    val_input_landmarks = input_landmarks[val_indices,:,:]
    val_target = target[val_indices]
    return train_input_im, train_input_landmarks, train_target, val_input_im, val_input_landmarks, val_target

def build_full_model(inputs_shape_image, inputs_shape_landmarks):
    # build image portion of model
    lra = 0.1
    input1 = tf.keras.layers.Input(shape=inputs_shape_image, name="inputs1")
    hid1 = tf.keras.layers.Conv2D(16,(3,3),padding='same')(input1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(16,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(16,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(256,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(256,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(64,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(512,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(64,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(512,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(1,1))(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(1000,(1,1),activation='linear')(hid1)
    hidden3 = tf.keras.layers.AveragePooling2D((1,1))(hid1)
    hidden6 = tf.keras.layers.Flatten()(hidden3)
    
    # build landmark portion of model
    input2 = tf.keras.layers.Input(shape=inputs_shape_landmarks, name="inputs2")
    hidden1 = tf.keras.layers.Dense(64, activation='relu')(input2)
    hidden2 = tf.keras.layers.Dense(32, activation='relu')(hidden1)
    hidden3 = tf.keras.layers.Dense(64, activation='relu')(hidden2)
    hidden4 = tf.keras.layers.Dense(32, activation='relu')(hidden3)
    hidden5 = tf.keras.layers.Dense(64, activation='relu')(hidden4)
    hidden16 = tf.keras.layers.Flatten()(hidden5)

    #concatenate components
    merged = tf.keras.layers.Concatenate(axis=1)([hidden6, hidden16])
    output = tf.keras.layers.Dense(4, use_bias=True, activation='softmax')(merged)

    model = tf.keras.models.Model(inputs=[input1, input2], outputs=output, name="ears_model")
    return model

def train_model(model, train_input, train_target, val_input, val_target, 
                epochs=20, learning_rate=0.01, batch_size=16):
    """
    Train the model on the given data
    :param model: Keras model
    :param train_input: train inputs
    :param train_target: train targets
    :param val_input: validation inputs
    :param val_target: validation targets
    :param epochs: epochs for gradient descent
    :param learning_rate: learning rate for gradient descent
    :param batch_size: batch size for training with gradient descent
    """
    if len(train_input)==2:
      ims = train_input[0]
      lms = train_input[1]
      ims = normalize_images(ims)
      train_input = [ims,lms]
      #val too
      ims_v = val_input[0]
      lms_v = val_input[1]
      ims_v = normalize_images(ims_v)
      val_input = [ims_v,lms_v]
    elif train_input.shape[1]==48:
      train_input = normalize_images(train_input)
      val_input = normalize_images(val_input)
    # compile the model: define optimizer, loss, and metrics
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),
                 loss='categorical_crossentropy',
                 metrics=['categorical_accuracy'])

    #Create callbacks for saving checkpoints and visualizing loss on TensorBoard
    logs_dir = 'logs3/log_{}'.format(datetime.datetime.now().strftime("%m-%d-%Y-%H-%M"))
    tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=logs_dir, write_graph=True)

    # save checkpoint callback
    checkpointCallBack = tf.keras.callbacks.ModelCheckpoint(os.path.join(logs_dir,'best_ears_weights.h5'),
                                                            monitor='categorical_accuracy',
                                                            verbose=0,
                                                            save_best_only=True,
                                                            save_weights_only=False,
                                                            mode='auto',
                                                            save_freq=1)

    # do training for the specified number of epochs and with the given batch size
    model.fit(train_input, train_target, 
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_data=(val_input, val_target),
                    callbacks=[tbCallBack, checkpointCallBack])

def test_model(model, test_input, batch_size=60):
    """
    Test a model on a given data
    :param model: trained model to perform testing on
    :param test_input: test inputs
    :return: predicted targets for the given inputs
    """
    if len(test_input)==2:
      ims = test_input[0]
      lms = test_input[1]
      ims = normalize_images(ims)
      test_input = [ims,lms]
    elif test_input.shape[1]==48:
      test_input = normalize_images(test_input)
    # evaluate
    predicted_targets = model.predict(test_input, batch_size=batch_size)
    return predicted_targets

"""#Load data"""

# initialize paths and input parameters
DATA_PATH = "/content/drive/My Drive/ears_features/full_data/"

# load data
input_images, targets, input_landmarks = load_data_from_path(DATA_PATH)

input_images = np.expand_dims(input_images, axis=3)

input_landmarks = np.expand_dims(input_landmarks, axis=3)

#input_images = normalize_images(input_images)

input_images = np.asarray(input_images)
input_landmarks = np.asarray(input_landmarks)
targets = np.asarray(targets)

print("SHAPES: ")
print(str(input_images.shape))
print(str(input_landmarks.shape))
print(str(targets.shape))

#split data into training and testing sets
all_train_input_im, all_train_input_landmarks, all_train_target, test_input_im, test_input_landmarks, test_target = split_data(input_images,input_landmarks,targets,0.8)

#split training set into training and validation sets
train_input_im, train_input_landmarks, train_target, val_input_im, val_input_landmarks, val_target = split_data(all_train_input_im, all_train_input_landmarks, all_train_target,0.6)

print(train_input_im.shape)
print(train_input_landmarks.shape)
print(train_target.shape)
print(val_input_im.shape)
print(val_input_landmarks.shape)
print(val_target.shape)
print(test_input_im.shape)
print(test_input_landmarks.shape)
print(test_target.shape)

"""#Load or build/train model

**Either** load model...
"""

## uncomment if want to load previosu model (2/5)

#name_of_model = "ears_model_tinydark12-07-2020-06-06.hdf5"

#model_path = F"/content/drive/My Drive/ears_features/models/"
#model = tf.keras.models.load_model(model_path + name_of_model)

"""**or** build model and train"""

# build the model
model = build_full_model(train_input_im.shape[1:], train_input_landmarks.shape[1:])

# set training parameters
batch_size = 256
epochs = 100
lr = 1e-4

# train the model
print("\n\nTRAINING...")
train_model(model, [train_input_im, train_input_landmarks], train_target, [val_input_im, val_input_landmarks], val_target,
            epochs=epochs, learning_rate=lr, batch_size=batch_size)

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs3

"""#Evaluate model"""

# find true labels for test dataset
true_labels = test_target.argmax(axis=1)

def evaluate_model_across_classes(model,test_input,true_labels,emotions):
  predicted_targets = test_model(model, test_input)
  predicted_labels = predicted_targets.argmax(axis=1)
  results = []
  for emotion in emotions:
    tp = np.sum(np.logical_and(true_labels==emotion,predicted_labels==emotion))
    tn = np.sum(np.logical_and(true_labels!=emotion,predicted_labels!=emotion))
    fp = np.sum(np.logical_and(true_labels!=emotion,predicted_labels==emotion))
    fn = np.sum(np.logical_and(true_labels==emotion,predicted_labels!=emotion))
    N = len(true_labels)
  
    acc = (tp+tn)/N
    mr = 1-acc
    precision = tp/(tp+fp)
    recall = tp/(tp+fn)
    f1 = (2*tp)/(2*tp+fp+fn)
    results.append([emotion,acc,mr,precision,recall,f1])
  cm = confusion_matrix(true_labels,predicted_labels)
  return np.asarray(results),cm

results,cm = evaluate_model_across_classes(model,[test_input_im,test_input_landmarks],true_labels,[0,1,2,3])

np.mean(results,axis=0)

cm

results

"""#Save model"""

custom_name = 'full_model_big_dataset'

print("saving model...")
model_path = F"/content/drive/My Drive/ears_features/models"
model_name = model_path + '/ears_model_' + custom_name + '_{}'.format(datetime.datetime.now().strftime("%m-%d-%Y-%H-%M"))
model_name = model_name + ".hdf5"
print(model_name)
model.save(model_name)

"""#Ablation study

Define functions to build ablation models
"""

def build_ablation_image(inputs_shape_image, inputs_shape_landmarks):
    lra = 0.1
    input1 = tf.keras.layers.Input(shape=inputs_shape_image, name="inputs1")
    hid1 = tf.keras.layers.Conv2D(16,(3,3),padding='same')(input1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(16,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(16,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(256,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(32,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(256,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same')(hid1)
    hid1 = tf.keras.layers.Conv2D(64,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(512,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(64,(1,1),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(512,(3,3),padding='same')(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(128,(1,1))(hid1)
    hid1 = tf.keras.layers.LeakyReLU(alpha=lra)(hid1)
    hid1 = tf.keras.layers.Conv2D(1000,(1,1),activation='linear')(hid1)
    hidden3 = tf.keras.layers.AveragePooling2D((1,1))(hid1)
    hidden6 = tf.keras.layers.Flatten()(hidden3)

    output = tf.keras.layers.Dense(4, use_bias=True, activation='softmax')(hidden6)

    model = tf.keras.models.Model(inputs=input1, outputs=output, name="ears_model_ai")
    return model

def build_ablation_landmarks(inputs_shape_image, inputs_shape_landmarks):
    # TRAIN THE LANDMARKS SEPARATELY
    input2 = tf.keras.layers.Input(shape=inputs_shape_landmarks, name="inputs2")
    hidden1 = tf.keras.layers.Dense(64, activation='relu')(input2)
    hidden2 = tf.keras.layers.Dense(32, activation='relu')(hidden1)
    hidden3 = tf.keras.layers.Dense(64, activation='relu')(hidden2)
    hidden4 = tf.keras.layers.Dense(32, activation='relu')(hidden3)
    hidden5 = tf.keras.layers.Dense(64, activation='relu')(hidden4)
    hidden16 = tf.keras.layers.Flatten()(hidden5)

    output = tf.keras.layers.Dense(4, use_bias=True, activation='softmax')(hidden16)

    model = tf.keras.models.Model(inputs=input2, outputs=output, name="ears_model_al")
    return model

"""Build and train the ablation models"""

# build the model
model_ai = build_ablation_image(train_input_im.shape[1:], train_input_landmarks.shape[1:])

# train the model
print("\n\nTRAINING...")
train_model(model_ai, train_input_im, train_target, val_input_im, val_target,
            epochs=epochs, learning_rate=lr, batch_size=batch_size)

# build the model
model_al = build_ablation_landmarks(train_input_im.shape[1:], train_input_landmarks.shape[1:])

# train the model
print("\n\nTRAINING...")
train_model(model_al, train_input_landmarks, train_target, val_input_landmarks, val_target,
            epochs=epochs, learning_rate=lr, batch_size=batch_size)

"""Evaluate the ablation model using only images"""

results_ai,cm_ai = evaluate_model_across_classes(model_ai,test_input_im,true_labels,[0,1,2,3])

np.mean(results_ai,axis=0)

results_ai

cm_ai

"""Evaluate ablation model using only landmarks"""

results_al,cm_al = evaluate_model_across_classes(model_al,test_input_landmarks,true_labels,[0,1,2,3])

results_al

np.mean(results_al,axis=0)

cm_al

"""Save ablation models"""

custom_name = 'ablation_images'

print("saving model...")
model_path = F"/content/drive/My Drive/ears_features/models"
model_name = model_path + '/ears_model_' + custom_name + '_{}'.format(datetime.datetime.now().strftime("%m-%d-%Y-%H-%M"))
model_name = model_name + ".hdf5"
print(model_name)
model_ai.save(model_name)

custom_name = 'ablation_landmarks'

print("saving model...")
model_path = F"/content/drive/My Drive/ears_features/models"
model_name = model_path + '/ears_model_' + custom_name + '_{}'.format(datetime.datetime.now().strftime("%m-%d-%Y-%H-%M"))
model_name = model_name + ".hdf5"
print(model_name)
model_al.save(model_name)